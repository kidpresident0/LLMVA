ğŸ¤ Local AI Voice Assistant (Push-to-Talk)
This project is a voice-controlled AI assistant that:

Listens when you hold the Shift key
Transcribes speech using Whisper
Sends the text to Ollama / LM Studio for AI responses
Speaks the response using Edge TTS

ğŸš€ Installation

âœ… Step 1: Clone the Repository

git clone https://github.com/your-repo-name/your-project-name.git
cd your-project-name
python -m venv .venv
source .venv/bin/activate  # Mac/Linux
.venv\Scripts\activate     # Windows

âœ… Step 3: Install Dependencies

pip install -r requirements.txt

ğŸ  Ollama Setup
Ollama is used to run local AI models for generating responses.

âœ… Step 1: Install Ollama
Windows / Mac / Linux: Download Ollama
Run the installer and restart your terminal after installation.

âœ… Step 2: Pull an AI Model
Before running the assistant, download an AI model (e.g., mistral):

ollama pull mistral
Other available models:

gemma
llama2
phi
codellama

âœ… Step 3: Start Ollama
Make sure Ollama is running in the background:

ollama serve

ğŸ™ï¸ Check Your Microphone Device Index
Run the following test script to find your microphone index:

import sounddevice as sd
print(sd.query_devices())
Update MIC_DEVICE_INDEX in assistant.py with your correct mic index.

ğŸ¬ Usage
Run the Assistant

python assistant.py

How to Use
Press & Hold the Shift key to record your question.
Release the Shift key â†’ The assistant transcribes & sends it to Ollama.
Ollama generates a response, and the assistant speaks it.

The answers can be rather long and detailed so press Escape if you want to cut off the spoken response.

ğŸ›  Troubleshooting
âŒ No AI Response?
Ensure Ollama is running (ollama serve).
Try switching models by updating MODEL_NAME in assistant.py.
âŒ Microphone Issues?
Check your mic index (sd.query_devices()).
Ensure your mic is set to 16-bit, 48000 Hz in Windows Sound Settings.
âŒ TTS (Speech) Doesnâ€™t Work?
Check console logs for âŒ ERROR: TTS output file was not created!
Ensure Edge TTS is installed (pip install edge-tts).

ğŸ¤ Contributing
Feel free to fork, modify, and submit pull requests! ğŸš€

ğŸ“œ License
MIT License - Use, modify, and distribute freely.

ğŸ‰ Now You Have a Local AI Voice Assistant!
ğŸš€ Try it out and let me know if you have any questions! ğŸ”¥ğŸ™ï¸







You said:
give me the readme in a format i can just copy paste
ChatGPT said:
Hereâ€™s the README.md in a clean copy-paste format:

md
Copy
Edit
# ğŸ¤ Local AI Voice Assistant (Push-to-Talk)

This project is a **voice-controlled AI assistant** that:
- **Listens when you hold the Space key**
- **Transcribes speech using Whisper**
- **Sends the text to Ollama for AI responses**
- **Speaks the response using Edge TTS**

---

## ğŸš€ Installation

### âœ… Step 1: Clone the Repository
```bash
git clone https://github.com/your-repo-name/your-project-name.git
cd your-project-name
âœ… Step 2: Set Up a Virtual Environment (Recommended)
bash
Copy
Edit
python -m venv .venv
source .venv/bin/activate  # Mac/Linux
.venv\Scripts\activate     # Windows
âœ… Step 3: Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
ğŸ  Ollama Setup
Ollama is used to run local AI models for generating responses.

âœ… Step 1: Install Ollama
Windows / Mac / Linux: Download Ollama
Run the installer and restart your terminal after installation.

âœ… Step 2: Pull an AI Model
Before running the assistant, download an AI model (e.g., mistral):

ollama pull mistral

Other available models:
gemma
llama2
phi
codellama

âœ… Step 3: Start Ollama
Make sure Ollama is running in the background:

ollama serve

ğŸ™ï¸ Check Your Microphone Device Index
Run the following test script to find your microphone index:

import sounddevice as sd
print(sd.query_devices())

Update MIC_DEVICE_INDEX in assistant.py with your correct mic index.

ğŸ¬ Usage
Run the Assistant

python assistant.py

How to Use

Press & Hold the Space key to record your question.
Release the Space key â†’ The assistant transcribes & sends it to Ollama.
Ollama generates a response, and the assistant speaks it.

ğŸ›  Troubleshooting
âŒ No AI Response?
Ensure Ollama is running (ollama serve).
Try switching models by updating MODEL_NAME in assistant.py.
âŒ Microphone Issues?
Check your mic index (sd.query_devices()).
Ensure your mic is set to 16-bit, 48000 Hz in Windows Sound Settings.
âŒ TTS (Speech) Doesnâ€™t Work?
Check console logs for âŒ ERROR: TTS output file was not created!
Ensure Edge TTS is installed (pip install edge-tts).
ğŸ¤ Contributing
Feel free to fork, modify, and submit pull requests! ğŸš€
